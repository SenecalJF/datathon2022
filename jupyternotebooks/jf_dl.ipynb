{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "import keras.models as models\n",
    "import keras.optimizers as optimizers\n",
    "import keras.wrappers.scikit_learn as kwrap\n",
    "import keras.callbacks as callbacks\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "X_train_path = '../data/train/X_train.csv'\n",
    "y_train_path = '../data/train/y_train.csv'\n",
    "X_test_path = '../data/test/X_test.csv'\n",
    "y_test_path = '../data/test/y_test.csv'\n",
    "\n",
    "X_train_df = pd.read_csv(X_train_path)\n",
    "y_train_df = pd.read_csv(y_train_path)\n",
    "X_test_df = pd.read_csv(X_test_path)\n",
    "y_test_df = pd.read_csv(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train/version1/dataset.csv'\n",
    "test_path = '../data/test/version1/dataset.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>w.bcpi_BCPI_WEEKLY</th>\n",
       "      <th>w.bcne_BCPI_WEEKLY</th>\n",
       "      <th>w.ener_BCPI_WEEKLY</th>\n",
       "      <th>w.mtls_BCPI_WEEKLY</th>\n",
       "      <th>w.fopr_BCPI_WEEKLY</th>\n",
       "      <th>w.agri_BCPI_WEEKLY</th>\n",
       "      <th>w.fish_BCPI_WEEKLY</th>\n",
       "      <th>v39078_CA.-interest_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>value_FRED_HSN1F</th>\n",
       "      <th>value_FRED_PAYEMS</th>\n",
       "      <th>value_FRED_PCEPILFE</th>\n",
       "      <th>value_FRED_RRSFS</th>\n",
       "      <th>value_FRED_UNRATE</th>\n",
       "      <th>fxusdcad_FXUSDCAD_rsi</th>\n",
       "      <th>rsi_FXUSDCAD_rsi</th>\n",
       "      <th>pmi_ISM_MAN_PMI</th>\n",
       "      <th>index_ISM_NONMAN_NMI</th>\n",
       "      <th>1 mo_USTREASURY_YIELD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>393.770000</td>\n",
       "      <td>303.210000</td>\n",
       "      <td>951.910000</td>\n",
       "      <td>488.660000</td>\n",
       "      <td>356.420000</td>\n",
       "      <td>207.020000</td>\n",
       "      <td>1293.840000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.331500</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>393.902857</td>\n",
       "      <td>303.647143</td>\n",
       "      <td>951.261429</td>\n",
       "      <td>489.705714</td>\n",
       "      <td>356.127143</td>\n",
       "      <td>207.402857</td>\n",
       "      <td>1298.995714</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.324400</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>394.035714</td>\n",
       "      <td>304.084286</td>\n",
       "      <td>950.612857</td>\n",
       "      <td>490.751429</td>\n",
       "      <td>355.834286</td>\n",
       "      <td>207.785714</td>\n",
       "      <td>1304.151429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.321400</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>394.168571</td>\n",
       "      <td>304.521429</td>\n",
       "      <td>949.964286</td>\n",
       "      <td>491.797143</td>\n",
       "      <td>355.541429</td>\n",
       "      <td>208.168571</td>\n",
       "      <td>1309.307143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.322267</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>394.301429</td>\n",
       "      <td>304.958571</td>\n",
       "      <td>949.315714</td>\n",
       "      <td>492.842857</td>\n",
       "      <td>355.248571</td>\n",
       "      <td>208.551429</td>\n",
       "      <td>1314.462857</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.323133</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>394.434286</td>\n",
       "      <td>305.395714</td>\n",
       "      <td>948.667143</td>\n",
       "      <td>493.888571</td>\n",
       "      <td>354.955714</td>\n",
       "      <td>208.934286</td>\n",
       "      <td>1319.618571</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.324000</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>394.567143</td>\n",
       "      <td>305.832857</td>\n",
       "      <td>948.018571</td>\n",
       "      <td>494.934286</td>\n",
       "      <td>354.662857</td>\n",
       "      <td>209.317143</td>\n",
       "      <td>1324.774286</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.321300</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>394.700000</td>\n",
       "      <td>306.270000</td>\n",
       "      <td>947.370000</td>\n",
       "      <td>495.980000</td>\n",
       "      <td>354.370000</td>\n",
       "      <td>209.700000</td>\n",
       "      <td>1329.930000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>395.265714</td>\n",
       "      <td>307.011429</td>\n",
       "      <td>947.797143</td>\n",
       "      <td>497.230000</td>\n",
       "      <td>355.254286</td>\n",
       "      <td>210.222857</td>\n",
       "      <td>1329.930000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.310600</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>395.831429</td>\n",
       "      <td>307.752857</td>\n",
       "      <td>948.224286</td>\n",
       "      <td>498.480000</td>\n",
       "      <td>356.138571</td>\n",
       "      <td>210.745714</td>\n",
       "      <td>1329.930000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>145818.0</td>\n",
       "      <td>107.357</td>\n",
       "      <td>193846.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.314100</td>\n",
       "      <td>41.796141</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date  w.bcpi_BCPI_WEEKLY  w.bcne_BCPI_WEEKLY  \\\n",
       "0           0  2017-01-04          393.770000          303.210000   \n",
       "1           1  2017-01-05          393.902857          303.647143   \n",
       "2           2  2017-01-06          394.035714          304.084286   \n",
       "3           3  2017-01-07          394.168571          304.521429   \n",
       "4           4  2017-01-08          394.301429          304.958571   \n",
       "5           5  2017-01-09          394.434286          305.395714   \n",
       "6           6  2017-01-10          394.567143          305.832857   \n",
       "7           7  2017-01-11          394.700000          306.270000   \n",
       "8           8  2017-01-12          395.265714          307.011429   \n",
       "9           9  2017-01-13          395.831429          307.752857   \n",
       "\n",
       "   w.ener_BCPI_WEEKLY  w.mtls_BCPI_WEEKLY  w.fopr_BCPI_WEEKLY  \\\n",
       "0          951.910000          488.660000          356.420000   \n",
       "1          951.261429          489.705714          356.127143   \n",
       "2          950.612857          490.751429          355.834286   \n",
       "3          949.964286          491.797143          355.541429   \n",
       "4          949.315714          492.842857          355.248571   \n",
       "5          948.667143          493.888571          354.955714   \n",
       "6          948.018571          494.934286          354.662857   \n",
       "7          947.370000          495.980000          354.370000   \n",
       "8          947.797143          497.230000          355.254286   \n",
       "9          948.224286          498.480000          356.138571   \n",
       "\n",
       "   w.agri_BCPI_WEEKLY  w.fish_BCPI_WEEKLY  v39078_CA.-interest_rate  ...  \\\n",
       "0          207.020000         1293.840000                      0.75  ...   \n",
       "1          207.402857         1298.995714                      0.75  ...   \n",
       "2          207.785714         1304.151429                      0.75  ...   \n",
       "3          208.168571         1309.307143                      0.75  ...   \n",
       "4          208.551429         1314.462857                      0.75  ...   \n",
       "5          208.934286         1319.618571                      0.75  ...   \n",
       "6          209.317143         1324.774286                      0.75  ...   \n",
       "7          209.700000         1329.930000                      0.75  ...   \n",
       "8          210.222857         1329.930000                      0.75  ...   \n",
       "9          210.745714         1329.930000                      0.75  ...   \n",
       "\n",
       "   value_FRED_HSN1F  value_FRED_PAYEMS  value_FRED_PCEPILFE  value_FRED_RRSFS  \\\n",
       "0             601.0           145818.0              107.357          193846.0   \n",
       "1             601.0           145818.0              107.357          193846.0   \n",
       "2             601.0           145818.0              107.357          193846.0   \n",
       "3             601.0           145818.0              107.357          193846.0   \n",
       "4             601.0           145818.0              107.357          193846.0   \n",
       "5             601.0           145818.0              107.357          193846.0   \n",
       "6             601.0           145818.0              107.357          193846.0   \n",
       "7             601.0           145818.0              107.357          193846.0   \n",
       "8             601.0           145818.0              107.357          193846.0   \n",
       "9             601.0           145818.0              107.357          193846.0   \n",
       "\n",
       "   value_FRED_UNRATE  fxusdcad_FXUSDCAD_rsi  rsi_FXUSDCAD_rsi  \\\n",
       "0                4.6               1.331500         41.796141   \n",
       "1                4.6               1.324400         41.796141   \n",
       "2                4.6               1.321400         41.796141   \n",
       "3                4.6               1.322267         41.796141   \n",
       "4                4.6               1.323133         41.796141   \n",
       "5                4.6               1.324000         41.796141   \n",
       "6                4.6               1.321300         41.796141   \n",
       "7                4.6               1.325000         41.796141   \n",
       "8                4.6               1.310600         41.796141   \n",
       "9                4.6               1.314100         41.796141   \n",
       "\n",
       "   pmi_ISM_MAN_PMI  index_ISM_NONMAN_NMI  1 mo_USTREASURY_YIELD  \n",
       "0             57.6                  57.4                   0.49  \n",
       "1             57.6                  57.4                   0.51  \n",
       "2             57.6                  57.4                   0.50  \n",
       "3             57.6                  57.4                   0.50  \n",
       "4             57.6                  57.4                   0.50  \n",
       "5             57.6                  57.4                   0.50  \n",
       "6             57.6                  57.4                   0.51  \n",
       "7             57.6                  57.4                   0.51  \n",
       "8             57.6                  57.4                   0.52  \n",
       "9             57.6                  57.4                   0.52  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = train.drop(['fxusdcad_FXUSDCAD_rsi','date'], axis=1).to_numpy(),train['fxusdcad_FXUSDCAD_rsi'].values\n",
    "X_test, y_test = test.drop(['fxusdcad_FXUSDCAD_rsi','date'], axis=1).to_numpy(),test['fxusdcad_FXUSDCAD_rsi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "# y_train = np.asarray(y_train_df)\n",
    "\n",
    "# test = np.asarray(X_test_df)\n",
    "# y_test = np.asarray(y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeanj\\Programming\\Maching learning\\Datathon-2022-data\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-2, input_shape=[23]):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    optimizer = optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "model = build_model(n_hidden=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "61/61 [==============================] - 1s 2ms/step - loss: nan  \n",
      "Epoch 2/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 3/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 4/20\n",
      "61/61 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 5/20\n",
      "61/61 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 6/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 7/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 8/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 9/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 10/20\n",
      "61/61 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 11/20\n",
      "61/61 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 12/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 13/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 14/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 15/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 16/20\n",
      "61/61 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 17/20\n",
      "61/61 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 18/20\n",
      "61/61 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 19/20\n",
      "61/61 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 20/20\n",
      "61/61 [==============================] - 0s 3ms/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(X_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1943,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to 0-1\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: -0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm = svm.SVR()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(svm.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6777294800290217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "y_pred_linearReg = reg.predict(X_test)\n",
    "reg.score(X_test, y_test)\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n",
    "xg_reg = xgb.XGBRegressor(colsample_bytree = 0.3, learning_rate = 0.06,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 200)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "polynomial_svm_reg = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=4)),\n",
    "        (\"svm_clf\", SVR(kernel=\"rbf\", C=5, coef0=1, gamma=5))\n",
    "    ])\n",
    "\n",
    "polynomial_svm_reg.fit(X_train, y_train)\n",
    "y_pred_poly = polynomial_svm_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "polynomiale_sgd_reg = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=2)),\n",
    "    (\"sgd_reg\", SGDRegressor(max_iter=1000, tol=1e-3, eta0=0.1))\n",
    "    ])\n",
    "# sgdReg = SGDRegressor(max_iter=10000, tol=1e-3, eta0=0.1, loss=\"epsilon_insensitive\")\n",
    "polynomiale_sgd_reg.fit(X_train, y_train)\n",
    "y_pred_sgd = polynomiale_sgd_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002732491383459811 xgboost\n",
      "-1.4651839538962341 xgboost\n",
      "0.0011494254827277243 svm\n",
      "-0.036982320739125774 svm\n",
      "0.001859650814581271 linear regression\n",
      "-0.6777294800290217 linear regression\n",
      "0.001226403261673922 polynomial regression\n",
      "-0.10642970733050183 polynomial regression\n",
      "0.027666821810489902 sgd regression\n",
      "-23.96030018443028 sgd regression\n"
     ]
    }
   ],
   "source": [
    "#calculate r2 score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(mse, 'xgboost')\n",
    "print(r2, 'xgboost')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(mse, 'svm')\n",
    "print(r2, 'svm')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_linearReg)\n",
    "r2 = r2_score(y_test, y_pred_linearReg)\n",
    "print(mse, 'linear regression')\n",
    "print(r2, 'linear regression')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_poly)\n",
    "r2 = r2_score(y_test, y_pred_poly)\n",
    "print(mse, 'polynomial regression')\n",
    "print(r2, 'polynomial regression')\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_sgd)\n",
    "r2 = r2_score(y_test, y_pred_sgd)\n",
    "print(mse, 'sgd regression')\n",
    "print(r2, 'sgd regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1943, 23)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 1, 32)             7168      \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 1, 16)             3136      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1, 1)              17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,321\n",
      "Trainable params: 10,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "55/55 [==============================] - 7s 30ms/step - loss: 0.8996 - accuracy: 0.0000e+00 - val_loss: 0.0888 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0875 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.0000e+00 - val_loss: 0.0514 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.0000e+00 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 9.7272e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.0000e+00 - val_loss: 9.5914e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 7.6315e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 7.1426e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 8.7373e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 9.4586e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.0000e+00 - val_loss: 7.2320e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 8.4946e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 9.7361e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 8.2847e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 9.1052e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 8.5173e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 7.9637e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 9.5806e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "#reshape data\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "model.add(LSTM(32, input_shape=(1, 23), return_sequences=True))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "y_pred_lstm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014426796263735302 y_pred_lstm_mse\n",
      "-0.30154872109639674 y_pred_lstm_r2\n"
     ]
    }
   ],
   "source": [
    "y_pred_lstm = y_pred_lstm.reshape(-1)\n",
    "print(mean_squared_error(y_test, y_pred_lstm), \"y_pred_lstm_mse\")\n",
    "print(r2_score(y_test, y_pred_lstm), \"y_pred_lstm_r2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd495b64596ba7dd17d77d1b04e38d9236653d58e5b7bd568f787c46e245586c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
